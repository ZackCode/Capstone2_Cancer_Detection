{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zexi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "100\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "200\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "300\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "400\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "500\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "600\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "700\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "800\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "900\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "1000\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "1100\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "1200\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "1300\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "1400\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "1500\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n",
      "This is unlabeled data!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "IMG_SIZE_PX = 50\n",
    "SLICE_COUNT = 20\n",
    "\n",
    "def chunks(l, n):\n",
    "    # Credit: Ned Batchelder\n",
    "    # Link: http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)\n",
    "\n",
    "\n",
    "def process_data(patient,labels_df,img_px_size=50, hm_slices=20, visualize=False):\n",
    "    \n",
    "    label = labels_df.get_value(patient, 'cancer')\n",
    "    path = data_dir + patient\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "    new_slices = []\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array),(img_px_size,img_px_size)) for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = int(math.ceil(len(slices) / hm_slices))\n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "        \n",
    "    while (len(new_slices) < hm_slices):\n",
    "        new_slices.append(new_slices[-1])\n",
    "        \n",
    "    while (len(new_slices) > hm_slices):\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "    \n",
    "    #if len(new_slices) == hm_slices-1:\n",
    "    #    new_slices.append(new_slices[-1])\n",
    "\n",
    "    #if len(new_slices) == hm_slices-2:\n",
    "    #    new_slices.append(new_slices[-1])\n",
    "    #    new_slices.append(new_slices[-1])\n",
    "        \n",
    "    #if len(new_slices) == hm_slices-3:\n",
    "    #    new_slices.append(new_slices[-1])\n",
    "    #   new_slices.append(new_slices[-1])\n",
    "    #    new_slices.append(new_slices[-1])\n",
    "    \n",
    "    #if len(new_slices) == hm_slices+3:\n",
    "    #    new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "    #    del new_slices[hm_slices]\n",
    "    #    new_slices[hm_slices-1] = new_val\n",
    "\n",
    "    #if len(new_slices) == hm_slices+2:\n",
    "    #    new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "    #    del new_slices[hm_slices]\n",
    "    #    new_slices[hm_slices-1] = new_val\n",
    "        \n",
    "    #if len(new_slices) == hm_slices+1:\n",
    "    #    new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "    #    del new_slices[hm_slices]\n",
    "    #    new_slices[hm_slices-1] = new_val\n",
    "\n",
    "    if visualize:\n",
    "        fig = plt.figure()\n",
    "        for num,each_slice in enumerate(new_slices):\n",
    "            y = fig.add_subplot(4,5,num+1)\n",
    "            y.imshow(each_slice, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    if label == 1: label=np.array([0,1])\n",
    "    elif label == 0: label=np.array([1,0])\n",
    "        \n",
    "    return np.array(new_slices),label\n",
    "\n",
    "#                                               stage 1 for real.\n",
    "data_dir = '../../cap2input/stage1/'\n",
    "patients = os.listdir(data_dir)\n",
    "labels = pd.read_csv('../../cap2input/stage1_labels.csv', index_col=0)\n",
    "\n",
    "much_data = []\n",
    "for num,patient in enumerate(patients):\n",
    "    if num % 100 == 0:\n",
    "        print(num)\n",
    "    try:\n",
    "        img_data,label = process_data(patient,labels,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\n",
    "        #print(img_data.shape,label)\n",
    "        much_data.append([img_data,label])\n",
    "    except KeyError as e:\n",
    "        print('This is unlabeled data!')\n",
    "\n",
    "np.save('muchdata-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), much_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE_PX = 50\n",
    "SLICE_COUNT = 20\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 10\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window as you slide about\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\n",
    "               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n",
    "               #                                  64 features\n",
    "               'W_fc':tf.Variable(tf.random_normal([54080,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "\n",
    "\n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 54080])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zexi/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('Epoch', 1, 'completed out of', 10, 'loss:', 266060085426.0)\n",
      "('Accuracy:', 0.71999991)\n",
      "('Epoch', 2, 'completed out of', 10, 'loss:', 18575149063.5)\n",
      "('Accuracy:', 0.64999998)\n",
      "('Epoch', 3, 'completed out of', 10, 'loss:', 6836563022.5625)\n",
      "('Accuracy:', 0.61000001)\n",
      "('Epoch', 4, 'completed out of', 10, 'loss:', 3775033645.0)\n",
      "('Accuracy:', 0.55999994)\n",
      "('Epoch', 5, 'completed out of', 10, 'loss:', 2334422391.1982422)\n",
      "('Accuracy:', 0.65999997)\n",
      "('Epoch', 6, 'completed out of', 10, 'loss:', 1670114653.375)\n",
      "('Accuracy:', 0.64999998)\n",
      "('Epoch', 7, 'completed out of', 10, 'loss:', 1055131791.625)\n",
      "('Accuracy:', 0.63)\n",
      "('Epoch', 8, 'completed out of', 10, 'loss:', 488071659.73464584)\n",
      "('Accuracy:', 0.51999998)\n",
      "('Epoch', 9, 'completed out of', 10, 'loss:', 244053330.6425032)\n",
      "('Accuracy:', 0.67000002)\n",
      "('Epoch', 10, 'completed out of', 10, 'loss:', 176309203.06231835)\n",
      "('Accuracy:', 0.45999998)\n",
      "Done. Finishing accuracy:\n",
      "('Accuracy:', 0.55999994)\n",
      "('fitment percent:', 1)\n"
     ]
    }
   ],
   "source": [
    "much_data = np.load('muchdata-50-50-20.npy')\n",
    "# If you are working with the basic sample data, use maybe 2 instead of 100 here... you don't have enough data to really do this\n",
    "train_data = much_data[:-100]\n",
    "validation_data = much_data[-100:]\n",
    "\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    \n",
    "    hm_epochs = 10\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        successful_runs = 0\n",
    "        total_runs = 0\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for data in train_data:\n",
    "                total_runs += 1\n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                    successful_runs += 1\n",
    "                except Exception as e:\n",
    "                    # I am passing for the sake of notebook space, but we are getting 1 shaping issue from one \n",
    "                    # input tensor. Not sure why, will have to look into it. Guessing it's\n",
    "                    # one of the depths that doesn't come to 20.\n",
    "                    pass\n",
    "                    #print(str(e))\n",
    "            \n",
    "            print('Epoch', epoch+1, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "            print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "            \n",
    "            #print accuracy\n",
    "            \n",
    "        print('Done. Finishing accuracy:')\n",
    "        print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "        \n",
    "        print('fitment percent:',successful_runs/total_runs)\n",
    "\n",
    "# Run this locally:\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zexi/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    72\n",
       "1    28\n",
       "Name: cancer, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.ix[-100:].cancer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
